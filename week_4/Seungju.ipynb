{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "442d5455-a426-4901-aeea-0b3e51e2e125",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text1\n",
      "what의 빈도수: 618번\n",
      "why의 빈도수: 119번\n",
      "when의 빈도수: 606번\n",
      "where의 빈도수: 220번\n",
      "which의 빈도수: 648번\n",
      "\n",
      "text2\n",
      "what의 빈도수: 444번\n",
      "why의 빈도수: 49번\n",
      "when의 빈도수: 306번\n",
      "where의 빈도수: 91번\n",
      "which의 빈도수: 593번\n",
      "\n",
      "text3\n",
      "what의 빈도수: 46번\n",
      "why의 빈도수: 8번\n",
      "when의 빈도수: 120번\n",
      "where의 빈도수: 25번\n",
      "which의 빈도수: 199번\n",
      "\n",
      "text4\n",
      "what의 빈도수: 183번\n",
      "why의 빈도수: 16번\n",
      "when의 빈도수: 221번\n",
      "where의 빈도수: 73번\n",
      "which의 빈도수: 1007번\n",
      "\n",
      "text5\n",
      "what의 빈도수: 201번\n",
      "why의 빈도수: 65번\n",
      "when의 빈도수: 54번\n",
      "where의 빈도수: 66번\n",
      "which의 빈도수: 6번\n",
      "\n",
      "text6\n",
      "what의 빈도수: 92번\n",
      "why의 빈도수: 7번\n",
      "when의 빈도수: 14번\n",
      "where의 빈도수: 14번\n",
      "which의 빈도수: 11번\n",
      "\n",
      "text7\n",
      "what의 빈도수: 71번\n",
      "why의 빈도수: 14번\n",
      "when의 빈도수: 98번\n",
      "where의 빈도수: 36번\n",
      "which의 빈도수: 225번\n",
      "\n",
      "text8\n",
      "what의 빈도수: 0번\n",
      "why의 빈도수: 0번\n",
      "when의 빈도수: 1번\n",
      "where의 빈도수: 0번\n",
      "which의 빈도수: 0번\n",
      "\n",
      "text9\n",
      "what의 빈도수: 171번\n",
      "why의 빈도수: 54번\n",
      "when의 빈도수: 140번\n",
      "where의 빈도수: 43번\n",
      "which의 빈도수: 199번\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1.\n",
    "\n",
    "\"\"\" import 해야할 것들 몰아서 import 해주기 \"\"\"\n",
    "\n",
    "# import nltk\n",
    "# from nltk.book import * \n",
    "# nltk.download('book',quiet =True) \n",
    "# from nltk import FreqDist\n",
    "\n",
    "\"\"\" getattr 사용해서 1부터 9까지 순회하여 각각의 text를 texts에 저장한다.\n",
    "ConditionalFreqDist를 이용하여 texts에 있는 text에서 word를 뽑아내 cfd에 저장한다.\n",
    "text_index 초기값을 0로 설정한다.\n",
    "texts에 있는 text를 순회하며\n",
    "    text_index 값을 1씩 증가시킨다.\n",
    "    각각의 text 번호를 출력한다.\n",
    "    \n",
    "    문제에서 구하고자 하는 'what','why','when','where','which'를 리스트에 담아 wh_words라는 변수에 저장한다.\n",
    "    wh_words의 단어를 순회하며 단어들의 빈도수를 출력한다.\n",
    "    가독성을 위해 빈 줄을 각 텍스트 사이에 출력한다.\n",
    "\"\"\"\n",
    "texts = [getattr(nltk.book, f'text{i}') for i in range(1,10)]\n",
    "\n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "    (text, word.lower()) for text in texts for word in text)\n",
    "\n",
    "text_index = 0\n",
    "for text in texts:\n",
    "    text_index += 1\n",
    "    print(f'text{text_index}')\n",
    "    \n",
    "    wh_words = ['what','why','when','where','which']\n",
    "    for word in wh_words:\n",
    "        print(f'{word}의 빈도수: {cfd[text][word]}번')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d366ac17-c6af-48d2-a7c8-52df8f28a21c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Parent s Assistant by Maria Edgeworth THE ORPHANS Near the ruins of the castle of Rossmore in Ireland is a small cabin in which there once lived a widow and her four children As long as she was able to work she was very industrious and was accounted the best spinner in the parish but she overworked herself at last and fell ill so that she could not sit to her wheel as she used to do and was obliged to give it up to her eldest daughter Mary Mary was at this time about twelve years old One eve\n"
     ]
    }
   ],
   "source": [
    "#2.\n",
    "\n",
    "\"\"\" import 해야할 것들 몰아서 import 해주기 \"\"\"\n",
    "\n",
    "# import nltk\n",
    "# from nltk.corpus import gutenberg\n",
    "# nltk.download(\"gutenberg\", quiet=True)\n",
    "\n",
    "\"\"\" 'a','e','i','o','u'를 리스트에 담아 vowels라는 변수에 저장한다.\n",
    " gutenberg의 file을 순회하며 파이릐 0번째 인덱싱, 즉 첫글자가 vowels에 있다면\n",
    "     알파벳인 것들만 뽑아내 clean_data라는 변수에 저장한다.\n",
    "     clean_data를 \" \"을 기준으로 붙여서 스트링 형식으로 변환한다.\n",
    "\n",
    "clean_data를 출력한다.\n",
    "\"\"\"\n",
    "\n",
    "vowels = ['a','e','i','o','u']\n",
    "\n",
    "for file in gutenberg.fileids():\n",
    "    if file[0] in vowels:\n",
    "        clean_data = [word for word in gutenberg.words(file) if word.isalpha()]\n",
    "        clean_data = \" \".join(clean_data)\n",
    "        \n",
    "print(clean_data[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6288af91-d534-49b1-829c-769f5fbc1efd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 장르별 hapax의 개수\n",
      "adventure: 4512개\n",
      "belles_lettres: 8556개\n",
      "editorial: 4967개\n",
      "fiction: 4838개\n",
      "government: 3347개\n",
      "hobbies: 5552개\n",
      "humor: 3173개\n",
      "learned: 7065개\n",
      "lore: 6945개\n",
      "mystery: 3452개\n",
      "news: 6834개\n",
      "religion: 3317개\n",
      "reviews: 4928개\n",
      "romance: 4329개\n",
      "science_fiction: 1896개\n"
     ]
    }
   ],
   "source": [
    "#3.\n",
    "\n",
    "\"\"\" import 해야할 것들 몰아서 import 해주기 \"\"\"\n",
    "\n",
    "# nltk.download('brown')\n",
    "# brown = nltk.corpus.brown\n",
    "\n",
    "\"\"\" ConditionalFreqDist을 이용하여\n",
    "브라운 카테고리에 있는 장르를 불러오고\n",
    "장르에 있는 단어들을 불러와서 cfd라는 변수에 저장한다.\n",
    "'각 장르별 hapax의 개수'라는 안내 문구를 출력한다.\n",
    "브라운의 카테고리를 순회하며\n",
    "장르별 hapax의 개수를 출력한다.\n",
    "\"\"\"\n",
    "\n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "    (genre,word.lower())\n",
    "    for genre in brown.categories()\n",
    "    for word in brown.words(categories=genre)\n",
    ")\n",
    "\n",
    "print('각 장르별 hapax의 개수')\n",
    "for genre in brown.categories():\n",
    "    print(f'{genre}: {len(cfd[genre].hapaxes())}개')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
